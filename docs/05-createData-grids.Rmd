---
title: "Create Data - Grids"
author: "Christopher Prener, Ph.D."
date: '(`r format(Sys.time(), "%B %d, %Y")`)'
output: 
  github_document: default
  html_notebook: default 
---

## Introduction
This notebook builds on the grid-level vacancy estimates created in `04-createData-vacancy.Rmd`. The crime and demographic data will be added to each grid square to create the neighborhood-level analysis data set.

## Dependencies
This notebook requires the following packages:

```{r load-packages}
# tidystl packages
library(compstatr)
library(stlcsb)

# tidyverse packages
library(dplyr)
library(readr)

# spatial packages
library(areal)
library(sf)
library(tigris)

# other packages
library(here)
```

## Load Base Data
All of the data will be interpolated into the grids that already contain vacancy metrics:

```{r load-grids}
# read
grids <- st_read(here("data", "raw", "grids"), stringsAsFactors = FALSE) %>%
  rename()

# re-project
grids <- st_transform(grids, crs = 26915)
```

## Add Arson Data
The arson data is stored in `arson.csv`. Since these are point data, I'll read them in, project them, and then use a spatial join to create counts per grid square. First, we'll load the data and project them:

```{r load-arson}
# load
arson <- read_csv(here("data", "clean", "point_arson.csv")) %>%
  filter(cs_year >= 2013 & cs_year <= 2017)

# project
arson <- cs_projectXY(arson, varX = x_coord, varY = y_coord, crs = 26915)

# print valid rows
nrow(arson)
```

Next, we'll perform the intersection:

```{r intersect-arson}
# project
arson <- st_intersection(arson, grids)

# print valid rows
nrow(arson)
```

Finally, we'll remove the geometry, sum our data by `grid_id`, and join our counts to the `grids` object:

```{r count-arson}
# remove geometry
st_geometry(arson) <- NULL

# perform spatial join
arson %>%
  group_by(grid_id) %>%
  summarize(arson = n()) %>%
  left_join(grids, ., by = "grid_id") %>%
  mutate(arson = ifelse(is.na(arson) == TRUE, 0, arson)) -> grids

# clean-up
rm(arson)
```

## Violent Crimes
The violent crime data is stored in `violent.csv`. As before, I'll read them in, project them, and then use a spatial join to create counts per grid square. First, we'll load the data and project them:

```{r load-violent}
# load
violent <- read_csv(here("data", "clean", "point_violent.csv"))

# project
violent <- cs_projectXY(violent, varX = x_coord, varY = y_coord, crs = 26915)

# print valid rows
nrow(violent)
```

Next, we'll perform the intersection:

```{r intersect-violent}
# project
violent <- st_intersection(violent, grids)

# print valid rows
nrow(violent)
```

Finally, we'll remove the geometry, sum our data by `grid_id`, and join our counts to the `grids` object:

```{r count-violent}
# remove geometry
st_geometry(violent) <- NULL

# perform spatial join
violent %>%
  group_by(grid_id) %>%
  summarize(violent = n()) %>%
  left_join(grids, ., by = "grid_id") %>%
  mutate(violent = ifelse(is.na(violent) == TRUE, 0, violent)) -> grids

# clean-up
rm(violent)
```

## Property Crimes
The property crime data is stored in `property.csv`. As before, I'll read them in, project them, and then use a spatial join to create counts per grid square. First, we'll load the data and project them:

```{r load-property}
# load
property <- read_csv(here("data", "clean", "point_property.csv"))

# project
property <- cs_projectXY(property, varX = x_coord, varY = y_coord, crs = 26915)

# print valid rows
nrow(property)
```

Next, we'll perform the intersection:

```{r intersect-property}
# project
property <- st_intersection(property, grids)

# print valid rows
nrow(property)
```

Finally, we'll remove the geometry, sum our data by `grid_id`, and join our counts to the `grids` object:

```{r count-property}
# remove geometry
st_geometry(property) <- NULL

# perform spatial join
property %>%
  group_by(grid_id) %>%
  summarize(property = n()) %>%
  left_join(grids, ., by = "grid_id") %>%
  mutate(property = ifelse(is.na(property) == TRUE, 0, property)) -> grids

# clean-up
rm(property)
```

## Other Crimes
The other crime data is stored in `otherCrimes.csv`. As before, I'll read them in, project them, and then use a spatial join to create counts per grid square. First, we'll load the data and project them:

```{r load-otherCrimes}
# load
otherCrimes <- read_csv(here("data", "clean", "point_otherCrimes.csv"))

# project
otherCrimes <- cs_projectXY(otherCrimes, varX = x_coord, varY = y_coord, crs = 26915)

# print valid rows
nrow(otherCrimes)
```

Next, we'll perform the intersection:

```{r intersect-otherCrimes}
# project
otherCrimes <- st_intersection(otherCrimes, grids)

# print valid rows
nrow(otherCrimes)
```

Finally, we'll remove the geometry, sum our data by `grid_id`, and join our counts to the `grids` object:

```{r count-otherCrimes}
# remove geometry
st_geometry(otherCrimes) <- NULL

# perform spatial join
otherCrimes %>%
  group_by(grid_id) %>%
  summarize(other_crime = n()) %>%
  left_join(grids, ., by = "grid_id") %>%
  mutate(other_crime = ifelse(is.na(other_crime) == TRUE, 0, other_crime)) -> grids

# clean-up
rm(otherCrimes)
```

## Disorder
The calls for disorder data are stored in `disorder.csv`. As before, I'll read them in, project them, and then use a spatial join to create counts per grid square. The project process varies slightly because these data are from a different source. First, we'll load the data and project them:

```{r load-disorder}
# load
disorder <- read_csv(here("data", "clean", "point_disorder.csv"))

# project
disorder <- csb_projectXY(disorder, varX = srx, varY = sry, crs = 26915)

# print valid rows
nrow(disorder)
```

Next, we'll perform the intersection:

```{r intersect-disorder}
# project
disorder <- st_intersection(disorder, grids)

# print valid rows
nrow(disorder)
```

Finally, we'll remove the geometry, sum our data by `grid_id`, and join our counts to the `grids` object:

```{r count-disorder}
# remove geometry
st_geometry(disorder) <- NULL

# perform spatial join
disorder %>%
  group_by(grid_id) %>%
  summarize(disorder = n()) %>%
  left_join(grids, ., by = "grid_id") %>%
  mutate(disorder = ifelse(is.na(disorder) == TRUE, 0, disorder)) -> grids

# clean-up
rm(disorder)
```

## Vacancy
The vacancy counts already correspond to the `grids` object, so they only need to be joined:

```{r join-vacancy}
# load
vacancy <- read_csv(here("data", "clean", "grids_vacancy.csv")) %>%
  select(grid_id, prop_vacant)

# join
grids <- left_join(grids, vacancy, by = "grid_id")

# clean-up
rm(vacancy)
```

## Contemporary Demographic Data
Our demographic measures are at the census tract level, which means they need to be interpolated into the grids. This process requires that the demographic data be merged with the corresponding geometric data. First, we'll download those data:

```{r download-tract-geometry}
tracts <- tracts(state = 29, county = 510, year = 2017, class = "sf") %>%
  select(GEOID)
```

Next, we'll load the demographic data and join them to the tract geometry:

```{r load-and-join-demos}
# load
demos <- read_csv(here("data", "clean", "tract_demographics.csv")) %>%
  mutate(GEOID = as.character(GEOID)) %>%
  select(GEOID, totalPop, medianInc, raceTotal, black, pvtyTotal, pvty, 
         emplyTotal, unemply, ownTotal, ownOcc) %>%
  rename(
    total_pop = totalPop,
    median_inc = medianInc
  )

# join
tracts <- left_join(tracts, demos, by = "GEOID")

# transform
tracts <- st_transform(tracts, crs = 26915)

# clean-up
rm(demos)
```

With our tract data prepared, we'll make a copy of the grids data that contain only the `grid_id` column:

```{r prep-grids}
grids_aw <- grids %>%
  select(grid_id)
```

Now that we have the grids and tract data ready to interpolate, we can perform the calculations:

```{r interpolate}
grids_aw_17 <- aw_interpolate(grids_aw, tid = grid_id, source = tracts, sid = GEOID,
                 weight = "sum", output = "tibble",
                 extensive = c("total_pop", "median_inc", "raceTotal", "black", 
                               "pvtyTotal", "pvty", "emplyTotal", "unemply",
                               "ownTotal", "ownOcc"))
```

Since we interpolated all spatially extensive measures, we need to calculate some relevant proportions and then remove the original count data:

```{r calculate-proportions}
grids_aw_17 %>%
  mutate(black_prop = black/raceTotal) %>%
  mutate(pvty_prop = pvty/pvtyTotal) %>%
  mutate(unemply_prop = unemply/emplyTotal) %>%
  mutate(ownOcc_prop = ownOcc/ownTotal) %>%
  select(-raceTotal, -black, -pvtyTotal, -pvty, 
         -emplyTotal, -unemply, -ownTotal, -ownOcc) -> grids_aw_17
```

Finally, we'll remove our raw data:

```{r clean-up}
rm(tracts)
```

## Historic Demographic Data
Next, we'll create estimates for both the 1950 total population and the 1970 total population at the grid level as well. First, we'll read the 1950 data in and then interplate it:

```{r estimate-1950}
# read tabular data
pop50 <- read_csv(here("data", "raw", "historic-population", "STL_DEMOGRAPHICS_pop50.csv")) %>%
  select(Geo_Name, SE_T001_001) %>%
  rename(
    TRACTID = Geo_Name,
    pop50 = SE_T001_001
  )

# read geometric data
tract50 <- st_read(here("data", "raw", "historic-population", "STL_DEMOGRAPHICS_tracts50"),
                   stringsAsFactors = FALSE) %>%
  st_transform(crs = 26915)

# join
pop50 <- left_join(tract50, pop50, by = "TRACTID")

# interpolate
grids_aw_50 <- aw_interpolate(grids_aw, tid = grid_id, source = pop50, sid = TRACTID,
                 weight = "sum", output = "tibble", extensive = "pop50")

# remove raw data
rm(pop50, tract50)
```

We'll the repeat the process with the 1970 era data:

```{r estimate-1970}
# read tabular data
pop70 <- read_csv(here("data", "raw", "historic-population", "STL_DEMOGRAPHICS_pop70.csv")) %>%
  select(Geo_TractCode, SE_T001_001) %>%
  rename(
    TRACTID = Geo_TractCode,
    pop70 = SE_T001_001
  )

# read geometric data
tract70 <- st_read(here("data", "raw", "historic-population", "STL_DEMOGRAPHICS_tracts70"),
                   stringsAsFactors = FALSE) %>%
  st_transform(crs = 26915)

# join
pop70 <- left_join(tract70, pop70, by = "TRACTID")

# interpolate
grids_aw_70 <- aw_interpolate(grids_aw, tid = grid_id, source = pop70, sid = TRACTID,
                 weight = "sum", output = "tibble", extensive = "pop70")

# remove raw data
rm(pop70, tract70)
```

## Combine Data
Finally, we'll combine our various measures into a single object:

```{r combine}
# joins
grids %>%
  left_join(., grids_aw_50, by = "grid_id") %>%
  left_join(., grids_aw_70, by = "grid_id") %>%
  left_join(., grids_aw_17, by = "grid_id") -> grids

# clean-up
rm(grids_aw_50, grids_aw_70, grids_aw_17, grids_aw)
```

## Write Data
With our data created, we can write the analytical data set to the `data/analysis` directory:

```{r write}
st_write(grids, dsn = here("data", "analysis", "spatial_analysis.geojson"),
         delete_dsn = TRUE)
```

Data are written in an open format to improve reproducibility.
